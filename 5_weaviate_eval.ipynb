{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "\n",
    "import os\n",
    "import textwrap as tr\n",
    "\n",
    "import nest_asyncio\n",
    "from azure.identity import DefaultAzureCredential, ManagedIdentityCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import ServiceContext, set_global_service_context\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.core.prompts import ChatMessage, ChatPromptTemplate, MessageRole\n",
    "from tqdm import tqdm\n",
    "\n",
    "# This is a hack to get some things to work in Jupyter Notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def pwrap(text):\n",
    "    print(tr.fill(str(text), width=80))\n",
    "\n",
    "# Load environment variables from .env file\n",
    "try:\n",
    "    load_dotenv(dotenv_path=\".env\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# If we're running on Azure, use the Managed Identity to get the secrets\n",
    "# if os.environ.get(\"CREDENTIAL_TYPE\").lower() == \"managed\":\n",
    "#     credential = ManagedIdentityCredential()\n",
    "# else:\n",
    "#     credential = DefaultAzureCredential()\n",
    "\n",
    "# # Login to KeyVault using Azure credentials\n",
    "# client = SecretClient(\n",
    "#     vault_url=os.environ.get(\"AZURE_KEYVAULT_URL\"), credential=credential\n",
    "# )\n",
    "\n",
    "OPENAI_API_BASE = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "OPENAI_API_VERSION = os.environ.get(\"AZURE_OPENAI_VERSION\")\n",
    "# OPENAI_API_KEY = client.get_secret(\"OPENAI-SERVICE-KEY\").value\n",
    "OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "api_key = OPENAI_API_KEY\n",
    "azure_endpoint = OPENAI_API_BASE\n",
    "api_version = OPENAI_API_VERSION\n",
    "\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    deployment_name=\"gpt-35-turbo\",\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-ada-002\",\n",
    "    deployment_name=\"text-embedding-ada-002\",\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "from llama_index.core import set_global_service_context\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    ")\n",
    "\n",
    "set_global_service_context(service_context)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
