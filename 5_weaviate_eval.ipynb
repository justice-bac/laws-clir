{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKuehn\\AppData\\Local\\Temp\\ipykernel_93392\\285261612.py:70: DeprecationWarning: Call to deprecated class method from_defaults. (ServiceContext is deprecated, please use `llama_index.settings.Settings` instead.) -- Deprecated since version 0.10.0.\n",
      "  service_context = ServiceContext.from_defaults(\n"
     ]
    }
   ],
   "source": [
    "# Setup\n",
    "\n",
    "import os\n",
    "import textwrap as tr\n",
    "\n",
    "import nest_asyncio\n",
    "from azure.identity import DefaultAzureCredential, ManagedIdentityCredential\n",
    "from azure.keyvault.secrets import SecretClient\n",
    "from dotenv import load_dotenv\n",
    "from llama_index.core import ServiceContext, set_global_service_context\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.core.prompts import ChatMessage, ChatPromptTemplate, MessageRole\n",
    "from tqdm import tqdm\n",
    "\n",
    "# This is a hack to get some things to work in Jupyter Notebooks\n",
    "nest_asyncio.apply()\n",
    "\n",
    "def pwrap(text):\n",
    "    print(tr.fill(str(text), width=80))\n",
    "\n",
    "# Load environment variables from .env file\n",
    "try:\n",
    "    load_dotenv(dotenv_path=\".env\")\n",
    "except:\n",
    "    pass\n",
    "\n",
    "# If we're running on Azure, use the Managed Identity to get the secrets\n",
    "# if os.environ.get(\"CREDENTIAL_TYPE\").lower() == \"managed\":\n",
    "#     credential = ManagedIdentityCredential()\n",
    "# else:\n",
    "#     credential = DefaultAzureCredential()\n",
    "\n",
    "# # Login to KeyVault using Azure credentials\n",
    "# client = SecretClient(\n",
    "#     vault_url=os.environ.get(\"AZURE_KEYVAULT_URL\"), credential=credential\n",
    "# )\n",
    "\n",
    "OPENAI_API_BASE = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "OPENAI_API_VERSION = os.environ.get(\"AZURE_OPENAI_VERSION\")\n",
    "# OPENAI_API_KEY = client.get_secret(\"OPENAI-SERVICE-KEY\").value\n",
    "OPENAI_API_KEY = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "\n",
    "api_key = OPENAI_API_KEY\n",
    "azure_endpoint = OPENAI_API_BASE\n",
    "api_version = OPENAI_API_VERSION\n",
    "\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=\"gpt-35-turbo\",\n",
    "    deployment_name=\"gpt-35-turbo\",\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=\"text-embedding-3-large\",\n",
    "    deployment_name=\"text-embedding-3-large\",\n",
    "    # dimensions=1024,\n",
    "    embed_batch_size=16,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "from llama_index.core import set_global_service_context\n",
    "\n",
    "service_context = ServiceContext.from_defaults(\n",
    "    llm=llm,\n",
    "    embed_model=embed_model,\n",
    ")\n",
    "\n",
    "set_global_service_context(service_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "df = pd.read_csv('small_df.csv')\n",
    "\n",
    "df.columns\n",
    "\n",
    "from llama_index.core.evaluation import EmbeddingQAFinetuneDataset\n",
    "from llama_index.core.schema import MetadataMode, TextNode\n",
    "import uuid\n",
    "\n",
    "eng_nodes = [TextNode(id=row['section_id'], text=row['text_combined_eng']) for index, row in df.iterrows()]\n",
    "fra_nodes = [TextNode(id=row['section_id'], text=row['text_combined_fra']) for index, row in df.iterrows()]\n",
    "eng_questions_easy = df['easy_eng_queries'].tolist()\n",
    "eng_questions_hard = df['hard_eng_queries'].tolist()\n",
    "fra_questions_easy = df['easy_fra_queries'].tolist()\n",
    "fra_questions_hard = df['hard_fra_queries'].tolist()\n",
    "\n",
    "def build_eval_dataset(nodes, questions):\n",
    "    \"\"\"Takes nodes and questions: 2 lists of the same length\"\"\"\n",
    "    node_dict = {\n",
    "        node.node_id: node.get_content(metadata_mode=MetadataMode.NONE)\n",
    "        for node in nodes\n",
    "    }\n",
    "    queries = {}\n",
    "    relevant_docs = {}\n",
    "\n",
    "    for node, question in zip(nodes, questions):\n",
    "        question_id = str(uuid.uuid4())\n",
    "        queries[question_id] = question\n",
    "        relevant_docs[question_id] = [node.node_id]\n",
    "\n",
    "    # construct dataset\n",
    "    return EmbeddingQAFinetuneDataset(\n",
    "        queries=queries, corpus=node_dict, relevant_docs=relevant_docs\n",
    "    )\n",
    "\n",
    "# TODO: add multi-language corpus\n",
    "# eng_to_eng_easy = build_eval_dataset(eng_nodes, eng_questions_easy)\n",
    "eng_to_eng_hard = build_eval_dataset(eng_nodes, eng_questions_hard)\n",
    "# fra_to_fra_easy = build_eval_dataset(fra_nodes, fra_questions_easy)\n",
    "fra_to_fra_hard = build_eval_dataset(fra_nodes, fra_questions_hard)\n",
    "# eng_to_fra_easy = build_eval_dataset(eng_nodes, fra_questions_easy)\n",
    "# eng_to_fra_hard = build_eval_dataset(eng_nodes, fra_questions_hard)\n",
    "# fra_to_eng_easy = build_eval_dataset(fra_nodes, eng_questions_easy)\n",
    "# fra_to_eng_hard = build_eval_dataset(fra_nodes, eng_questions_hard)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Weaviate base.py\n",
    "# Changed to use relative score fusion \n",
    "\n",
    "\"\"\"Weaviate Vector store index.\n",
    "\n",
    "An index that is built on top of an existing vector store.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "import logging\n",
    "from typing import Any, Dict, List, Optional, cast\n",
    "from uuid import uuid4\n",
    "\n",
    "from llama_index.core.bridge.pydantic import Field, PrivateAttr\n",
    "from llama_index.core.schema import BaseNode\n",
    "from llama_index.core.vector_stores.types import (\n",
    "    BasePydanticVectorStore,\n",
    "    MetadataFilters,\n",
    "    VectorStoreQuery,\n",
    "    VectorStoreQueryMode,\n",
    "    VectorStoreQueryResult,\n",
    ")\n",
    "from llama_index.core.vector_stores.utils import DEFAULT_TEXT_KEY\n",
    "from llama_index.vector_stores.weaviate.utils import (\n",
    "    add_node,\n",
    "    class_schema_exists,\n",
    "    create_default_schema,\n",
    "    get_all_properties,\n",
    "    get_node_similarity,\n",
    "    parse_get_response,\n",
    "    to_node,\n",
    ")\n",
    "\n",
    "import weaviate  # noqa\n",
    "from weaviate import AuthApiKey, Client\n",
    "from weaviate.gql.get import HybridFusion\n",
    "\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "\n",
    "def _transform_weaviate_filter_condition(condition: str) -> str:\n",
    "    \"\"\"Translate standard metadata filter op to Chroma specific spec.\"\"\"\n",
    "    if condition == \"and\":\n",
    "        return \"And\"\n",
    "    elif condition == \"or\":\n",
    "        return \"Or\"\n",
    "    else:\n",
    "        raise ValueError(f\"Filter condition {condition} not supported\")\n",
    "\n",
    "\n",
    "def _transform_weaviate_filter_operator(operator: str) -> str:\n",
    "    \"\"\"Translate standard metadata filter operator to Chroma specific spec.\"\"\"\n",
    "    if operator == \"!=\":\n",
    "        return \"NotEqual\"\n",
    "    elif operator == \"==\":\n",
    "        return \"Equal\"\n",
    "    elif operator == \">\":\n",
    "        return \"GreaterThan\"\n",
    "    elif operator == \"<\":\n",
    "        return \"LessThan\"\n",
    "    elif operator == \">=\":\n",
    "        return \"GreaterThanEqual\"\n",
    "    elif operator == \"<=\":\n",
    "        return \"LessThanEqual\"\n",
    "    else:\n",
    "        raise ValueError(f\"Filter operator {operator} not supported\")\n",
    "\n",
    "\n",
    "def _to_weaviate_filter(standard_filters: MetadataFilters) -> Dict[str, Any]:\n",
    "    filters_list = []\n",
    "    condition = standard_filters.condition or \"and\"\n",
    "    condition = _transform_weaviate_filter_condition(condition)\n",
    "\n",
    "    if standard_filters.filters:\n",
    "        for filter in standard_filters.filters:\n",
    "            value_type = \"valueText\"\n",
    "            if isinstance(filter.value, float):\n",
    "                value_type = \"valueNumber\"\n",
    "            elif isinstance(filter.value, int):\n",
    "                value_type = \"valueInt\"\n",
    "            elif isinstance(filter.value, str) and filter.value.isnumeric():\n",
    "                filter.value = float(filter.value)\n",
    "                value_type = \"valueNumber\"\n",
    "            filters_list.append(\n",
    "                {\n",
    "                    \"path\": filter.key,\n",
    "                    \"operator\": _transform_weaviate_filter_operator(filter.operator),\n",
    "                    value_type: filter.value,\n",
    "                }\n",
    "            )\n",
    "    else:\n",
    "        return {}\n",
    "\n",
    "    if len(filters_list) == 1:\n",
    "        # If there is only one filter, return it directly\n",
    "        return filters_list[0]\n",
    "\n",
    "    return {\"operands\": filters_list, \"operator\": condition}\n",
    "\n",
    "\n",
    "class WeaviateVectorStore(BasePydanticVectorStore):\n",
    "    \"\"\"Weaviate vector store.\n",
    "\n",
    "    In this vector store, embeddings and docs are stored within a\n",
    "    Weaviate collection.\n",
    "\n",
    "    During query time, the index uses Weaviate to query for the top\n",
    "    k most similar nodes.\n",
    "\n",
    "    Args:\n",
    "        weaviate_client (weaviate.Client): WeaviateClient\n",
    "            instance from `weaviate-client` package\n",
    "        index_name (Optional[str]): name for Weaviate classes\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    stores_text: bool = True\n",
    "\n",
    "    index_name: str\n",
    "    url: Optional[str]\n",
    "    text_key: str\n",
    "    auth_config: Dict[str, Any] = Field(default_factory=dict)\n",
    "    client_kwargs: Dict[str, Any] = Field(default_factory=dict)\n",
    "\n",
    "    _client = PrivateAttr()\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        weaviate_client: Optional[Any] = None,\n",
    "        class_prefix: Optional[str] = None,\n",
    "        index_name: Optional[str] = None,\n",
    "        text_key: str = DEFAULT_TEXT_KEY,\n",
    "        auth_config: Optional[Any] = None,\n",
    "        client_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        url: Optional[str] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> None:\n",
    "        \"\"\"Initialize params.\"\"\"\n",
    "        if weaviate_client is None:\n",
    "            if isinstance(auth_config, dict):\n",
    "                auth_config = AuthApiKey(**auth_config)\n",
    "\n",
    "            client_kwargs = client_kwargs or {}\n",
    "            self._client = Client(\n",
    "                url=url, auth_client_secret=auth_config, **client_kwargs\n",
    "            )\n",
    "        else:\n",
    "            self._client = cast(Client, weaviate_client)\n",
    "\n",
    "        # validate class prefix starts with a capital letter\n",
    "        if class_prefix is not None:\n",
    "            logger.warning(\"class_prefix is deprecated, please use index_name\")\n",
    "            # legacy, kept for backward compatibility\n",
    "            index_name = f\"{class_prefix}_Node\"\n",
    "\n",
    "        index_name = index_name or f\"LlamaIndex_{uuid4().hex}\"\n",
    "        if not index_name[0].isupper():\n",
    "            raise ValueError(\n",
    "                \"Index name must start with a capital letter, e.g. 'LlamaIndex'\"\n",
    "            )\n",
    "\n",
    "        # create default schema if does not exist\n",
    "        if not class_schema_exists(self._client, index_name):\n",
    "            create_default_schema(self._client, index_name)\n",
    "\n",
    "        super().__init__(\n",
    "            url=url,\n",
    "            index_name=index_name,\n",
    "            text_key=text_key,\n",
    "            auth_config=auth_config.__dict__ if auth_config else {},\n",
    "            client_kwargs=client_kwargs or {},\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def from_params(\n",
    "        cls,\n",
    "        url: str,\n",
    "        auth_config: Any,\n",
    "        index_name: Optional[str] = None,\n",
    "        text_key: str = DEFAULT_TEXT_KEY,\n",
    "        client_kwargs: Optional[Dict[str, Any]] = None,\n",
    "        **kwargs: Any,\n",
    "    ) -> \"WeaviateVectorStore\":\n",
    "        \"\"\"Create WeaviateVectorStore from config.\"\"\"\n",
    "        client_kwargs = client_kwargs or {}\n",
    "        weaviate_client = Client(\n",
    "            url=url, auth_client_secret=auth_config, **client_kwargs\n",
    "        )\n",
    "        return cls(\n",
    "            weaviate_client=weaviate_client,\n",
    "            url=url,\n",
    "            auth_config=auth_config.__dict__,\n",
    "            client_kwargs=client_kwargs,\n",
    "            index_name=index_name,\n",
    "            text_key=text_key,\n",
    "            **kwargs,\n",
    "        )\n",
    "\n",
    "    @classmethod\n",
    "    def class_name(cls) -> str:\n",
    "        return \"WeaviateVectorStore\"\n",
    "\n",
    "    @property\n",
    "    def client(self) -> Any:\n",
    "        \"\"\"Get client.\"\"\"\n",
    "        return self._client\n",
    "\n",
    "    def add(\n",
    "        self,\n",
    "        nodes: List[BaseNode],\n",
    "        **add_kwargs: Any,\n",
    "    ) -> List[str]:\n",
    "        \"\"\"Add nodes to index.\n",
    "\n",
    "        Args:\n",
    "            nodes: List[BaseNode]: list of nodes with embeddings\n",
    "\n",
    "        \"\"\"\n",
    "        ids = [r.node_id for r in nodes]\n",
    "\n",
    "        with self._client.batch as batch:\n",
    "            for node in nodes:\n",
    "                add_node(\n",
    "                    self._client,\n",
    "                    node,\n",
    "                    self.index_name,\n",
    "                    batch=batch,\n",
    "                    text_key=self.text_key,\n",
    "                )\n",
    "        return ids\n",
    "\n",
    "    def delete(self, ref_doc_id: str, **delete_kwargs: Any) -> None:\n",
    "        \"\"\"\n",
    "        Delete nodes using with ref_doc_id.\n",
    "\n",
    "        Args:\n",
    "            ref_doc_id (str): The doc_id of the document to delete.\n",
    "\n",
    "        \"\"\"\n",
    "        where_filter = {\n",
    "            \"path\": [\"ref_doc_id\"],\n",
    "            \"operator\": \"Equal\",\n",
    "            \"valueText\": ref_doc_id,\n",
    "        }\n",
    "        if \"filter\" in delete_kwargs and delete_kwargs[\"filter\"] is not None:\n",
    "            where_filter = {\n",
    "                \"operator\": \"And\",\n",
    "                \"operands\": [where_filter, delete_kwargs[\"filter\"]],  # type: ignore\n",
    "            }\n",
    "\n",
    "        query = (\n",
    "            self._client.query.get(self.index_name)\n",
    "            .with_additional([\"id\"])\n",
    "            .with_where(where_filter)\n",
    "            .with_limit(10000)  # 10,000 is the max weaviate can fetch\n",
    "        )\n",
    "\n",
    "        query_result = query.do()\n",
    "        parsed_result = parse_get_response(query_result)\n",
    "        entries = parsed_result[self.index_name]\n",
    "        for entry in entries:\n",
    "            self._client.data_object.delete(entry[\"_additional\"][\"id\"], self.index_name)\n",
    "\n",
    "    def query(self, query: VectorStoreQuery, **kwargs: Any) -> VectorStoreQueryResult:\n",
    "        \"\"\"Query index for top k most similar nodes.\"\"\"\n",
    "        all_properties = get_all_properties(self._client, self.index_name)\n",
    "\n",
    "        # build query\n",
    "        query_builder = self._client.query.get(self.index_name, all_properties)\n",
    "\n",
    "        # list of documents to constrain search\n",
    "        if query.doc_ids:\n",
    "            filter_with_doc_ids = {\n",
    "                \"operator\": \"Or\",\n",
    "                \"operands\": [\n",
    "                    {\"path\": [\"doc_id\"], \"operator\": \"Equal\", \"valueText\": doc_id}\n",
    "                    for doc_id in query.doc_ids\n",
    "                ],\n",
    "            }\n",
    "            query_builder = query_builder.with_where(filter_with_doc_ids)\n",
    "\n",
    "        if query.node_ids:\n",
    "            filter_with_node_ids = {\n",
    "                \"operator\": \"Or\",\n",
    "                \"operands\": [\n",
    "                    {\"path\": [\"id\"], \"operator\": \"Equal\", \"valueText\": node_id}\n",
    "                    for node_id in query.node_ids\n",
    "                ],\n",
    "            }\n",
    "            query_builder = query_builder.with_where(filter_with_node_ids)\n",
    "\n",
    "        query_builder = query_builder.with_additional(\n",
    "            [\"id\", \"vector\", \"distance\", \"score\"]\n",
    "        )\n",
    "\n",
    "        vector = query.query_embedding\n",
    "        similarity_key = \"distance\"\n",
    "        if query.mode == VectorStoreQueryMode.DEFAULT:\n",
    "            logger.debug(\"Using vector search\")\n",
    "            if vector is not None:\n",
    "                query_builder = query_builder.with_near_vector(\n",
    "                    {\n",
    "                        \"vector\": vector,\n",
    "                    }\n",
    "                )\n",
    "        elif query.mode == VectorStoreQueryMode.HYBRID:\n",
    "            logger.debug(f\"Using hybrid search with alpha {query.alpha}\")\n",
    "            similarity_key = \"score\"\n",
    "            if vector is not None and query.query_str:\n",
    "                query_builder = query_builder.with_hybrid(\n",
    "                    query=query.query_str,\n",
    "                    alpha=query.alpha,\n",
    "                    vector=vector,\n",
    "                    fusion_type=HybridFusion.RELATIVE_SCORE,\n",
    "                )\n",
    "\n",
    "        if query.filters is not None:\n",
    "            filter = _to_weaviate_filter(query.filters)\n",
    "            query_builder = query_builder.with_where(filter)\n",
    "        elif \"filter\" in kwargs and kwargs[\"filter\"] is not None:\n",
    "            query_builder = query_builder.with_where(kwargs[\"filter\"])\n",
    "\n",
    "        query_builder = query_builder.with_limit(query.similarity_top_k)\n",
    "        logger.debug(f\"Using limit of {query.similarity_top_k}\")\n",
    "\n",
    "        # execute query\n",
    "        query_result = query_builder.do()\n",
    "\n",
    "        # parse results\n",
    "        parsed_result = parse_get_response(query_result)\n",
    "        entries = parsed_result[self.index_name]\n",
    "\n",
    "        similarities = []\n",
    "        nodes: List[BaseNode] = []\n",
    "        node_ids = []\n",
    "\n",
    "        for i, entry in enumerate(entries):\n",
    "            if i < query.similarity_top_k:\n",
    "                similarities.append(get_node_similarity(entry, similarity_key))\n",
    "                nodes.append(to_node(entry, text_key=self.text_key))\n",
    "                node_ids.append(nodes[-1].node_id)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return VectorStoreQueryResult(\n",
    "            nodes=nodes, ids=node_ids, similarities=similarities\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\JKuehn\\AppData\\Roaming\\Python\\Python311\\site-packages\\weaviate\\warnings.py:121: DeprecationWarning: Dep005: You are using weaviate-client version 3.26.2. The latest version is 4.5.5.\n",
      "            Please consider upgrading to the latest version. See https://weaviate.io/developers/weaviate/client-libraries/python for details.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import weaviate\n",
    "\n",
    "client = weaviate.Client(\"http://localhost:8080\")\n",
    "\n",
    "from llama_index.core import (\n",
    "    SimpleDirectoryReader,\n",
    "    StorageContext,\n",
    "    VectorStoreIndex,\n",
    ")\n",
    "\n",
    "client.schema.delete_class(\"LawsCLIR\")\n",
    "eng_vector_store = WeaviateVectorStore(\n",
    "    weaviate_client=client, index_name=\"LawsCLIR\"\n",
    ")\n",
    "eng_index = VectorStoreIndex.from_vector_store(\n",
    "    eng_vector_store, embed_model=embed_model\n",
    ")\n",
    "eng_index.insert_nodes(eng_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.evaluation import RetrieverEvaluator\n",
    "import pandas as pd\n",
    "\n",
    "def display_results(name, eval_results):\n",
    "    \"\"\"Display results from evaluate.\"\"\"\n",
    "\n",
    "    metric_dicts = []\n",
    "    for eval_result in eval_results:\n",
    "        metric_dict = eval_result.metric_vals_dict\n",
    "        metric_dicts.append(metric_dict)\n",
    "\n",
    "    full_df = pd.DataFrame(metric_dicts)\n",
    "\n",
    "    hit_rate = full_df[\"hit_rate\"].mean()\n",
    "    mrr = full_df[\"mrr\"].mean()\n",
    "    columns = {\"retrievers\": [name], \"hit_rate\": [hit_rate], \"mrr\": [mrr]}\n",
    "\n",
    "    # if include_cohere_rerank:\n",
    "    #     crr_relevancy = full_df[\"cohere_rerank_relevancy\"].mean()\n",
    "    #     columns.update({\"cohere_rerank_relevancy\": [crr_relevancy]})\n",
    "\n",
    "    metric_df = pd.DataFrame(columns)\n",
    "\n",
    "    return metric_df\n",
    "\n",
    "metrics = [\"mrr\", \"hit_rate\"]\n",
    "\n",
    "eng_retriever = eng_index.as_retriever(\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    similarity_top_k=5,\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "eng_hybrid_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    metrics, retriever=eng_retriever,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_hybrid</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958367</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retrievers  hit_rate       mrr         test_set\n",
       "0  eng_hybrid     0.992  0.958367  eng_to_eng_hard"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_hybrid = await eng_hybrid_evaluator.aevaluate_dataset(eng_to_eng_hard)\n",
    "\n",
    "result1 = display_results(\"eng_hybrid\", eng_hybrid)\n",
    "result1[\"test_set\"] = \"eng_to_eng_hard\"\n",
    "\n",
    "result1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_hybrid</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958367</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_vector</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958650</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retrievers  hit_rate       mrr         test_set\n",
       "0  eng_hybrid     0.992  0.958367  eng_to_eng_hard\n",
       "0  eng_vector     0.992  0.958650  eng_to_eng_hard"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_vector_retriever = eng_index.as_retriever(\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    similarity_top_k=5,\n",
    "    alpha=1,\n",
    ")\n",
    "\n",
    "eng_vector_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    metrics, retriever=eng_vector_retriever,\n",
    ")\n",
    "\n",
    "eng_vector = await eng_vector_evaluator.aevaluate_dataset(eng_to_eng_hard)\n",
    "\n",
    "result2 = display_results(\"eng_vector\", eng_vector)\n",
    "result2[\"test_set\"] = \"eng_to_eng_hard\"\n",
    "\n",
    "pd.concat([result1, result2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_hybrid</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958367</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_vector</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958650</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_bm25</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.791517</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retrievers  hit_rate       mrr         test_set\n",
       "0  eng_hybrid     0.992  0.958367  eng_to_eng_hard\n",
       "0  eng_vector     0.992  0.958650  eng_to_eng_hard\n",
       "0    eng_bm25     0.915  0.791517  eng_to_eng_hard"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_more_bm25_retriever = eng_index.as_retriever(\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    similarity_top_k=5,\n",
    "    alpha=0.3,\n",
    ")\n",
    "\n",
    "eng_more_bm25_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    metrics, retriever=eng_more_bm25_retriever,\n",
    ")\n",
    "\n",
    "eng_bm25 = await eng_more_bm25_evaluator.aevaluate_dataset(eng_to_eng_hard)\n",
    "\n",
    "result3 = display_results(\"eng_bm25\", eng_bm25)\n",
    "result3[\"test_set\"] = \"eng_to_eng_hard\"\n",
    "\n",
    "pd.concat([result1, result2, result3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.schema.delete_class(\"LawsCLIRfr\")\n",
    "fra_vector_store = WeaviateVectorStore(\n",
    "    weaviate_client=client, index_name=\"LawsCLIRfr\"\n",
    ")\n",
    "fra_index = VectorStoreIndex.from_vector_store(\n",
    "    fra_vector_store, embed_model=embed_model\n",
    ")\n",
    "fra_index.insert_nodes(fra_nodes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_hybrid</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958367</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_vector</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958650</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_bm25</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.791517</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fra_hybrid</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.931417</td>\n",
       "      <td>fra_to_fra_hard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retrievers  hit_rate       mrr         test_set\n",
       "0  eng_hybrid     0.992  0.958367  eng_to_eng_hard\n",
       "0  eng_vector     0.992  0.958650  eng_to_eng_hard\n",
       "0    eng_bm25     0.915  0.791517  eng_to_eng_hard\n",
       "0  fra_hybrid     0.985  0.931417  fra_to_fra_hard"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_retriever = fra_index.as_retriever(\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    similarity_top_k=5,\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "fra_hybrid_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    metrics, retriever=fra_retriever,\n",
    ")\n",
    "\n",
    "fra_hybrid = await fra_hybrid_evaluator.aevaluate_dataset(fra_to_fra_hard)\n",
    "\n",
    "result4 = display_results(\"fra_hybrid\", fra_hybrid)\n",
    "\n",
    "result4[\"test_set\"] = \"fra_to_fra_hard\"\n",
    "\n",
    "pd.concat([result1, result2, result3, result4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_hybrid</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958367</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_vector</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958650</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_bm25</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.791517</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fra_hybrid</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.931417</td>\n",
       "      <td>fra_to_fra_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fra_vector</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.924833</td>\n",
       "      <td>fra_to_fra_hard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retrievers  hit_rate       mrr         test_set\n",
       "0  eng_hybrid     0.992  0.958367  eng_to_eng_hard\n",
       "0  eng_vector     0.992  0.958650  eng_to_eng_hard\n",
       "0    eng_bm25     0.915  0.791517  eng_to_eng_hard\n",
       "0  fra_hybrid     0.985  0.931417  fra_to_fra_hard\n",
       "0  fra_vector     0.977  0.924833  fra_to_fra_hard"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_vector_retriever = fra_index.as_retriever(\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    similarity_top_k=5,\n",
    "    alpha=1,\n",
    ")\n",
    "\n",
    "fra_vector_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    metrics, retriever=fra_vector_retriever,\n",
    ")\n",
    "\n",
    "fra_vector = await fra_vector_evaluator.aevaluate_dataset(fra_to_fra_hard)\n",
    "\n",
    "result5 = display_results(\"fra_vector\", fra_vector)\n",
    "\n",
    "result5[\"test_set\"] = \"fra_to_fra_hard\"\n",
    "\n",
    "pd.concat([result1, result2, result3, result4, result5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_hybrid</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958367</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_vector</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958650</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_bm25</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.791517</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fra_hybrid</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.931417</td>\n",
       "      <td>fra_to_fra_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fra_vector</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.924833</td>\n",
       "      <td>fra_to_fra_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fra_bm25</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.767817</td>\n",
       "      <td>fra_to_fra_hard</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   retrievers  hit_rate       mrr         test_set\n",
       "0  eng_hybrid     0.992  0.958367  eng_to_eng_hard\n",
       "0  eng_vector     0.992  0.958650  eng_to_eng_hard\n",
       "0    eng_bm25     0.915  0.791517  eng_to_eng_hard\n",
       "0  fra_hybrid     0.985  0.931417  fra_to_fra_hard\n",
       "0  fra_vector     0.977  0.924833  fra_to_fra_hard\n",
       "0    fra_bm25     0.899  0.767817  fra_to_fra_hard"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_more_bm25_retriever = fra_index.as_retriever(\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    similarity_top_k=5,\n",
    "    alpha=0.3,\n",
    ")\n",
    "\n",
    "fra_more_bm25_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    metrics, retriever=fra_more_bm25_retriever,\n",
    ")\n",
    "\n",
    "fra_bm25 = await fra_more_bm25_evaluator.aevaluate_dataset(fra_to_fra_hard)\n",
    "\n",
    "result6 = display_results(\"fra_bm25\", fra_bm25)\n",
    "\n",
    "result6[\"test_set\"] = \"fra_to_fra_hard\"\n",
    "\n",
    "pd.concat([result1, result2, result3, result4, result5, result6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "eng_to_fra_hard = build_eval_dataset(eng_nodes, fra_questions_hard)\n",
    "fra_to_eng_hard = build_eval_dataset(fra_nodes, eng_questions_hard)\n",
    "\n",
    "eng_to_fra_retriever = eng_index.as_retriever(\n",
    "    vector_store_query_mode=\"hybrid\",\n",
    "    similarity_top_k=5,\n",
    "    alpha=0.7,\n",
    ")\n",
    "\n",
    "eng_to_fra_evaluator = RetrieverEvaluator.from_metric_names(\n",
    "    metrics, retriever=eng_to_fra_retriever,\n",
    ")\n",
    "\n",
    "eng_to_fra = await eng_to_fra_evaluator.aevaluate_dataset(eng_to_fra_hard)\n",
    "\n",
    "result7 = display_results(\"french_q_english_corpus_hybrid\", eng_to_fra)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_hybrid</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958367</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_vector</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958650</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_bm25</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.791517</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fra_hybrid</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.931417</td>\n",
       "      <td>fra_to_fra_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fra_vector</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.924833</td>\n",
       "      <td>fra_to_fra_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fra_bm25</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.767817</td>\n",
       "      <td>fra_to_fra_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>french_q_english_corpus_hybrid</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.874967</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english_q_french_corpus_hybrid</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.931717</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       retrievers  hit_rate       mrr         test_set\n",
       "0                      eng_hybrid     0.992  0.958367  eng_to_eng_hard\n",
       "0                      eng_vector     0.992  0.958650  eng_to_eng_hard\n",
       "0                        eng_bm25     0.915  0.791517  eng_to_eng_hard\n",
       "0                      fra_hybrid     0.985  0.931417  fra_to_fra_hard\n",
       "0                      fra_vector     0.977  0.924833  fra_to_fra_hard\n",
       "0                        fra_bm25     0.899  0.767817  fra_to_fra_hard\n",
       "0  french_q_english_corpus_hybrid     0.960  0.874967              NaN\n",
       "0  english_q_french_corpus_hybrid     0.988  0.931717              NaN"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fra_to_eng = await fra_hybrid_evaluator.aevaluate_dataset(fra_to_eng_hard)\n",
    "\n",
    "result8 = display_results(\"english_q_french_corpus_hybrid\", fra_to_eng)\n",
    "\n",
    "pd.concat([result1, result2, result3, result4, result5, result6, result7, result8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>retrievers</th>\n",
       "      <th>hit_rate</th>\n",
       "      <th>mrr</th>\n",
       "      <th>test_set</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_hybrid</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958367</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_vector</td>\n",
       "      <td>0.992</td>\n",
       "      <td>0.958650</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>eng_bm25</td>\n",
       "      <td>0.915</td>\n",
       "      <td>0.791517</td>\n",
       "      <td>eng_to_eng_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fra_hybrid</td>\n",
       "      <td>0.985</td>\n",
       "      <td>0.931417</td>\n",
       "      <td>fra_to_fra_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fra_vector</td>\n",
       "      <td>0.977</td>\n",
       "      <td>0.924833</td>\n",
       "      <td>fra_to_fra_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>fra_bm25</td>\n",
       "      <td>0.899</td>\n",
       "      <td>0.767817</td>\n",
       "      <td>fra_to_fra_hard</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>french_q_english_corpus_hybrid</td>\n",
       "      <td>0.960</td>\n",
       "      <td>0.874967</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english_q_french_corpus_hybrid</td>\n",
       "      <td>0.988</td>\n",
       "      <td>0.931717</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>french_q_english_corpus_vector</td>\n",
       "      <td>0.959</td>\n",
       "      <td>0.883433</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>english_q_french_corpus_vector</td>\n",
       "      <td>0.981</td>\n",
       "      <td>0.935383</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       retrievers  hit_rate       mrr         test_set\n",
       "0                      eng_hybrid     0.992  0.958367  eng_to_eng_hard\n",
       "0                      eng_vector     0.992  0.958650  eng_to_eng_hard\n",
       "0                        eng_bm25     0.915  0.791517  eng_to_eng_hard\n",
       "0                      fra_hybrid     0.985  0.931417  fra_to_fra_hard\n",
       "0                      fra_vector     0.977  0.924833  fra_to_fra_hard\n",
       "0                        fra_bm25     0.899  0.767817  fra_to_fra_hard\n",
       "0  french_q_english_corpus_hybrid     0.960  0.874967              NaN\n",
       "0  english_q_french_corpus_hybrid     0.988  0.931717              NaN\n",
       "0  french_q_english_corpus_vector     0.959  0.883433              NaN\n",
       "0  english_q_french_corpus_vector     0.981  0.935383              NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eng_to_fra_vector = await eng_vector_evaluator.aevaluate_dataset(eng_to_fra_hard)\n",
    "fra_to_eng_vector = await fra_vector_evaluator.aevaluate_dataset(fra_to_eng_hard)\n",
    "\n",
    "result9 = display_results(\"french_q_english_corpus_vector\", eng_to_fra_vector)\n",
    "result10 = display_results(\"english_q_french_corpus_vector\", fra_to_eng_vector)\n",
    "\n",
    "pd.concat([result1, result2, result3, result4, result5, result6, result7, result8, result9, result10])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
